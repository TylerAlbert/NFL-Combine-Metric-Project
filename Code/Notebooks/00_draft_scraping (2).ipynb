{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cc7ec46-5f60-4e9c-a92c-af7f8791f0ef",
   "metadata": {},
   "source": [
    "# Tyler Albert, Jake Angelucci\n",
    "## Data Wrangling Project Fall 2024\n",
    "### Website Scraped: https://www.pro-football-reference.com/years/2010/draft.htm\n",
    "### Webite homepage: https://www.pro-football-reference.com/\n",
    "#### In this notebook we will be scraping the url above for data on players drafted into the NFL from years 2009-2019. We will be scraping for the year the player was drafted, the overall pick number, the players name, and their position. Note that in our code we had to use an f-string in our url to ensure that the scraping would only be between a certain year range, so that \"2010\" in the data would vary depending on which year was currently being scraped. Above is listed the homepage of the website, we then naviagted to the \"draft\" page and selected year \"2009\" to start our scrape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a7fc448-7353-409f-886a-33c57ab3e6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing URL: https://www.pro-football-reference.com/years/2009/draft.htm\n",
      "Accessing URL: https://www.pro-football-reference.com/years/2010/draft.htm\n",
      "Accessing URL: https://www.pro-football-reference.com/years/2011/draft.htm\n",
      "Accessing URL: https://www.pro-football-reference.com/years/2012/draft.htm\n",
      "Accessing URL: https://www.pro-football-reference.com/years/2013/draft.htm\n",
      "Accessing URL: https://www.pro-football-reference.com/years/2014/draft.htm\n",
      "Accessing URL: https://www.pro-football-reference.com/years/2015/draft.htm\n",
      "Accessing URL: https://www.pro-football-reference.com/years/2016/draft.htm\n",
      "Accessing URL: https://www.pro-football-reference.com/years/2017/draft.htm\n",
      "Accessing URL: https://www.pro-football-reference.com/years/2018/draft.htm\n",
      "Accessing URL: https://www.pro-football-reference.com/years/2019/draft.htm\n",
      "Data saved to players_draft_data_2009_2019.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Setup ChromeDriver using webdriver_manager\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run in headless mode\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "service = Service(ChromeDriverManager().install())\n",
    "browser = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# Function to scroll down the page randomly\n",
    "def random_scroll(browser, total_wait_time=5):\n",
    "    total_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "    scroll_steps = random.randint(3, 7)\n",
    "    scroll_increment = total_height // scroll_steps\n",
    "    time_per_step = total_wait_time / scroll_steps\n",
    "    for step in range(scroll_steps):\n",
    "        browser.execute_script(\"window.scrollBy(0, arguments[0]);\", scroll_increment)\n",
    "        time.sleep(random.uniform(0.5 * time_per_step, 1.5 * time_per_step))\n",
    "    browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "# Function to scrape draft data from the page\n",
    "def scrape_draft(browser):\n",
    "    picks = []\n",
    "    players = []\n",
    "    positions = []\n",
    "    \n",
    "    try:\n",
    "        # Wait until the table is present\n",
    "        WebDriverWait(browser, 10).until(\n",
    "            EC.presence_of_element_located((By.XPATH, '//table[contains(@id,\"drafts\")]'))\n",
    "        )\n",
    "        \n",
    "        # Locate the draft table rows\n",
    "        table_rows = browser.find_elements(By.XPATH, '//table[contains(@id,\"drafts\")]//tbody//tr')\n",
    "        \n",
    "        for row in table_rows:\n",
    "            try:\n",
    "                cells = row.find_elements(By.TAG_NAME, 'td')\n",
    "                \n",
    "                # Skip rows that are not data rows\n",
    "                if len(cells) > 3:  # Ensure the row has enough columns\n",
    "                    draft_pick = cells[0].text  # \"pick\" column\n",
    "                    player = cells[2].text     # \"player\" column\n",
    "                    position = cells[3].text   # \"position\" column\n",
    "                    \n",
    "                    # Append data only if all required fields are present\n",
    "                    if draft_pick and player and position:\n",
    "                        picks.append(draft_pick)\n",
    "                        players.append(player)\n",
    "                        positions.append(position)\n",
    "            except Exception as e:\n",
    "                print(f\"Error encountered while processing row: {e}\")\n",
    "                continue\n",
    "    except Exception as e:\n",
    "        print(f\"Error encountered while locating table rows: {e}\")\n",
    "    \n",
    "    return picks, players, positions\n",
    "\n",
    "# List to hold all data\n",
    "all_picks = []\n",
    "all_players = []\n",
    "all_positions = []\n",
    "all_years = []\n",
    "\n",
    "# Years to scrape\n",
    "years = list(range(2009, 2020))\n",
    "\n",
    "# Scrape data for each year\n",
    "for year in years:\n",
    "    try:\n",
    "        url = f'https://www.pro-football-reference.com/years/{year}/draft.htm'\n",
    "        print(f\"Accessing URL: {url}\")\n",
    "        browser.get(url)\n",
    "        time.sleep(random.uniform(3, 7))\n",
    "        random_scroll(browser)\n",
    "        \n",
    "        picks, players, positions = scrape_draft(browser)\n",
    "        all_picks.extend(picks)\n",
    "        all_players.extend(players)\n",
    "        all_positions.extend(positions)\n",
    "        all_years.extend([year] * len(players))\n",
    "    except Exception as e:\n",
    "        print(f\"Error encountered for year {year}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Create DataFrame\n",
    "draft_data = pd.DataFrame({\n",
    "    'Year': all_years,\n",
    "    'Overall Pick': all_picks,\n",
    "    'Player Name': all_players,\n",
    "    'Position': all_positions\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "if not draft_data.empty:\n",
    "    draft_data.to_csv('players_draft_data_2009_2019.csv', index=False)\n",
    "    print(\"Data saved to players_draft_data_2009_2019.csv\")\n",
    "else:\n",
    "    print(\"No data scraped. The DataFrame is empty.\")\n",
    "\n",
    "# Close the browser\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "082ae47c-6193-4fb3-92eb-7112fab2dd07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Overall Pick</th>\n",
       "      <th>Player Name</th>\n",
       "      <th>Position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>Matthew Stafford</td>\n",
       "      <td>QB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>2</td>\n",
       "      <td>Jason Smith</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009</td>\n",
       "      <td>3</td>\n",
       "      <td>Tyson Jackson</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>Aaron Curry</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009</td>\n",
       "      <td>5</td>\n",
       "      <td>Mark Sanchez</td>\n",
       "      <td>QB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Overall Pick       Player Name Position\n",
       "0  2009             1  Matthew Stafford       QB\n",
       "1  2009             2       Jason Smith        T\n",
       "2  2009             3     Tyson Jackson       DE\n",
       "3  2009             4       Aaron Curry       LB\n",
       "4  2009             5      Mark Sanchez       QB"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scraped_draft = pd.read_csv('players_draft_data_2009_2019.csv')\n",
    "display(scraped_draft.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea630a40-373a-4302-9627-177d5dcedb69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
